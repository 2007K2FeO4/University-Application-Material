{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "687d7447-2cff-4067-ac47-18521476e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywikibot as pwb\n",
    "import webbrowser as wb\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List\n",
    "\n",
    "site = pwb.Site(\"en\", \"marble_kingdoms\")  # (language_code, family)\n",
    "site.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37067171-43d1-4846-9a48-24a277cbfe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Marble Kingdoms hero scraping...\n",
      "Logged in as: Louisa-Bot\n",
      "Processing MK 3...\n",
      "  No hero data found in MK 3\n",
      "Processing MK 4...\n",
      "  No hero data found in MK 4\n",
      "Processing MK 5...\n",
      "  No hero data found in MK 5\n",
      "Processing MK 6...\n",
      "  No hero data found in MK 6\n",
      "Processing MK 7...\n",
      "  No hero data found in MK 7\n",
      "Processing MK 8...\n",
      "  No hero data found in MK 8\n",
      "Processing MK 9...\n",
      "  No hero data found in MK 9\n",
      "Processing MK 10...\n",
      "  No hero data found in MK 10\n",
      "Processing MK 11...\n",
      "  No hero data found in MK 11\n",
      "Processing MK 12...\n",
      "  No hero data found in MK 12\n",
      "Processing MK 13...\n",
      "  No hero data found in MK 13\n",
      "Processing MK 14...\n",
      "  No hero data found in MK 14\n",
      "Processing MK 15...\n",
      "  No hero data found in MK 15\n",
      "Processing MK 16...\n",
      "  No hero data found in MK 16\n",
      "Processing MK 17...\n",
      "  No hero data found in MK 17\n",
      "Processing MK 18...\n",
      "  No hero data found in MK 18\n",
      "Processing MK 19...\n",
      "  No hero data found in MK 19\n",
      "Processing MK 20...\n",
      "  No hero data found in MK 20\n",
      "Processing MK 21...\n",
      "  No hero data found in MK 21\n",
      "Processing MK 22...\n",
      "  No hero data found in MK 22\n",
      "Processing MK 23...\n",
      "  No hero data found in MK 23\n",
      "Processing MK 24...\n",
      "  No hero data found in MK 24\n",
      "Processing MK 25...\n",
      "  No hero data found in MK 25\n",
      "Processing MK 26...\n",
      "  No hero data found in MK 26\n",
      "Processing MK 27...\n",
      "  No hero data found in MK 27\n",
      "Processing MK 28...\n",
      "  No hero data found in MK 28\n",
      "Processing MK 29...\n",
      "  No hero data found in MK 29\n",
      "Processing MK 30...\n",
      "  No hero data found in MK 30\n",
      "Processing MK 31...\n",
      "  No hero data found in MK 31\n",
      "Processing MK 32...\n",
      "  No hero data found in MK 32\n",
      "Processing MK 33...\n",
      "  No hero data found in MK 33\n",
      "Processing MK 34...\n",
      "  No hero data found in MK 34\n",
      "Processing MK 35...\n",
      "  No hero data found in MK 35\n",
      "Processing MK 36...\n",
      "  No hero data found in MK 36\n",
      "Processing MK 37...\n",
      "  No hero data found in MK 37\n",
      "\n",
      "============================================================\n",
      "MARBLE KINGDOMS HEROES DATABASE\n",
      "============================================================\n",
      "\n",
      "SUMMARY: 0 episodes, 0 levels, 0 hero appearances\n",
      "Data saved to marble_kingdoms_heroes.json\n",
      "Data saved to marble_kingdoms_heroes.csv\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Open JSON file? (y/n):  n\n"
     ]
    }
   ],
   "source": [
    "def get_episode_data() -> Dict[str, Dict[str, List[str]]]:\n",
    "    \"\"\"Get all episode data using pywikibot\"\"\"\n",
    "    all_episodes = {}\n",
    "    \n",
    "    # Process episodes 3 through 37\n",
    "    for episode_num in range(3, 38):\n",
    "        page_title = f\"MK {episode_num}\"\n",
    "        try:\n",
    "            page = pwb.Page(site, page_title)\n",
    "            if page.exists():\n",
    "                print(f\"Processing {page_title}...\")\n",
    "                episode_data = parse_episode_page(page)\n",
    "                if episode_data:\n",
    "                    all_episodes[page_title] = episode_data\n",
    "                    print(f\"  Found {sum(len(heroes) for heroes in episode_data.values())} heroes in {len(episode_data)} levels\")\n",
    "                else:\n",
    "                    print(f\"  No hero data found in {page_title}\")\n",
    "            else:\n",
    "                print(f\"Page {page_title} does not exist\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {page_title}: {e}\")\n",
    "    \n",
    "    return all_episodes\n",
    "\n",
    "def parse_episode_page(page: pwb.Page) -> Dict[str, List[str]]:\n",
    "    \"\"\"Parse a single episode page to extract heroes by level\"\"\"\n",
    "    episode_data = {}\n",
    "    wikitext = page.text\n",
    "    \n",
    "    # Find the \"Heroes of MK X\" section using a more robust pattern\n",
    "    heroes_pattern = r'==+[^=]*Heroes of MK[^=]*==+(.*?)(?==+=|\\{\\{|$)'\n",
    "    heroes_section_match = re.search(heroes_pattern, wikitext, re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    if not heroes_section_match:\n",
    "        # Try alternative pattern in case the section naming varies\n",
    "        heroes_pattern_alt = r'==+[^=]*Heroes[^=]*==+(.*?)(?==+=|\\{\\{|$)'\n",
    "        heroes_section_match = re.search(heroes_pattern_alt, wikitext, re.IGNORECASE | re.DOTALL)\n",
    "        \n",
    "        if not heroes_section_match:\n",
    "            return {}\n",
    "    \n",
    "    heroes_section = heroes_section_match.group(1)\n",
    "    \n",
    "    # Find all level sections (Level X, Special, Stage X, etc.)\n",
    "    level_pattern = r'===+([^=]+)===+(.*?)(?===+=|\\{\\{|$)'\n",
    "    \n",
    "    for match in re.finditer(level_pattern, heroes_section, re.DOTALL):\n",
    "        level_name = match.group(1).strip()\n",
    "        level_content = match.group(2).strip()\n",
    "        \n",
    "        # Check if this is actually a level section (not some other heading)\n",
    "        if not re.match(r'(?i)(level|stage|special|lvl)\\s*\\d*', level_name) and 'special' not in level_name.lower():\n",
    "            continue\n",
    "        \n",
    "        # Extract hero names from wikilinks [[Hero Name]] or [[Hero Name|display text]]\n",
    "        heroes = []\n",
    "        \n",
    "        # Method 1: Direct wikilink patterns\n",
    "        wikilink_matches = re.findall(r'\\[\\[([^\\]|]+)(?:\\|[^\\]]*)?\\]\\]', level_content)\n",
    "        for hero in wikilink_matches:\n",
    "            hero_name = hero.strip()\n",
    "            if hero_name and hero_name not in heroes:\n",
    "                heroes.append(hero_name)\n",
    "        \n",
    "        # Method 2: Look for bullet lists with hero names\n",
    "        if not heroes:\n",
    "            bullet_lines = re.findall(r'\\*+\\s*\\[\\[([^\\]|]+)', level_content)\n",
    "            for hero in bullet_lines:\n",
    "                hero_name = hero.strip()\n",
    "                if hero_name and hero_name not in heroes:\n",
    "                    heroes.append(hero_name)\n",
    "        \n",
    "        # Method 3: Look for comma-separated hero names in paragraphs\n",
    "        if not heroes:\n",
    "            # Find text that might contain hero names\n",
    "            text_blocks = re.split(r'\\n\\n+', level_content)\n",
    "            for block in text_blocks:\n",
    "                if '[[[' in block:  # Likely contains wikilinks\n",
    "                    block_heroes = re.findall(r'\\[\\[([^\\]|]+)(?:\\|[^\\]]*)?\\]\\]', block)\n",
    "                    for hero in block_heroes:\n",
    "                        hero_name = hero.strip()\n",
    "                        if hero_name and hero_name not in heroes:\n",
    "                            heroes.append(hero_name)\n",
    "        \n",
    "        if heroes:\n",
    "            episode_data[level_name] = heroes\n",
    "    \n",
    "    return episode_data\n",
    "\n",
    "def save_to_json(data: Dict, filename: str = 'marble_kingdoms_heroes.json'):\n",
    "    \"\"\"Save the data to a JSON file\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "def save_to_csv(data: Dict, filename: str = 'marble_kingdoms_heroes.csv'):\n",
    "    \"\"\"Save the data to a CSV file using pandas\"\"\"\n",
    "    rows = []\n",
    "    for episode, levels in data.items():\n",
    "        for level, heroes in levels.items():\n",
    "            for hero in heroes:\n",
    "                rows.append({\n",
    "                    'episode': episode,\n",
    "                    'level': level,\n",
    "                    'hero': hero\n",
    "                })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(filename, index=False, encoding='utf-8')\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "def display_results(data: Dict):\n",
    "    \"\"\"Display the results in a readable format\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MARBLE KINGDOMS HEROES DATABASE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for episode, levels in data.items():\n",
    "        print(f\"\\n{episode}\")\n",
    "        for level, heroes in levels.items():\n",
    "            print(f\"  --{level}\")\n",
    "            print(f\"    ----{', '.join(heroes)}\")\n",
    "    \n",
    "    total_episodes = len(data)\n",
    "    total_levels = sum(len(levels) for levels in data.values())\n",
    "    total_heroes = sum(len(heroes) for levels in data.values() for heroes in levels.values())\n",
    "    \n",
    "    print(f\"\\nSUMMARY: {total_episodes} episodes, {total_levels} levels, {total_heroes} hero appearances\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the scraping process\"\"\"\n",
    "    print(\"Starting Marble Kingdoms hero scraping...\")\n",
    "    print(\"Logged in as:\", site.user())\n",
    "    \n",
    "    # Get all episode data\n",
    "    heroes_dict = get_episode_data()\n",
    "    \n",
    "    # Display results\n",
    "    display_results(heroes_dict)\n",
    "    \n",
    "    # Save to files\n",
    "    save_to_json(heroes_dict)\n",
    "    save_to_csv(heroes_dict)\n",
    "    \n",
    "    # Optional: Open the JSON file in default application\n",
    "    if input(\"\\nOpen JSON file? (y/n): \").lower() == 'y':\n",
    "        wb.open('marble_kingdoms_heroes.json')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca170536-6c25-4291-8078-fc2b50e9ffcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing extraction with MK 17...\n",
      "\n",
      "============================================================\n",
      "DEBUGGING EXTRACTION FOR: MK 17\n",
      "============================================================\n",
      "ðŸ“‹ HEROES SECTION CONTENT:\n",
      "----------------------------------------\n",
      "\"''Monks and Kingsguards debuted in this episode.''\\n\"\n",
      "----------------------------------------\n",
      "ðŸ” Found 0 level sections\n",
      "âŒ NO LEVEL SECTIONS FOUND! Trying alternative patterns...\n",
      "Alternative pattern 1: Found 0 matches\n",
      "Alternative pattern 2: Found 0 matches\n",
      "Alternative pattern 3: Found 0 matches\n",
      "\n",
      "ðŸŽ¯ DEBUG RESULT: {}\n",
      "ðŸŽ¯ FINAL RESULT: {}\n"
     ]
    }
   ],
   "source": [
    "def debug_episode_extraction(page: pwb.Page) -> Dict[str, List[str]]:\n",
    "    \"\"\"Debug function to show exactly what's extracted from an episode\"\"\"\n",
    "    episode_data = {}\n",
    "    wikitext = page.text\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"DEBUGGING EXTRACTION FOR: {page.title()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Show the raw heroes section first - use a more flexible pattern\n",
    "    heroes_match = re.search(r'== Heroes of MK \\d+ ==\\s*\\n(.*?)(?=\\n==|\\n\\{\\{|$)', wikitext, re.DOTALL)\n",
    "    \n",
    "    if not heroes_match:\n",
    "        print(\"âŒ NO HEROES SECTION FOUND!\")\n",
    "        return {}\n",
    "    \n",
    "    heroes_section = heroes_match.group(1)\n",
    "    print(\"ðŸ“‹ HEROES SECTION CONTENT:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(repr(heroes_section))  # Use repr to see hidden characters\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Find all level subsections - FIXED PATTERN with optional spaces\n",
    "    level_pattern = r'===+\\s*(Level \\d+|Special|Stage \\d+)\\s*===+\\s*\\n(.*?)(?=\\n===+|\\n==|\\n\\{\\{|$)'\n",
    "    level_matches = list(re.finditer(level_pattern, heroes_section, re.DOTALL))\n",
    "    \n",
    "    print(f\"ðŸ” Found {len(level_matches)} level sections\")\n",
    "    \n",
    "    if not level_matches:\n",
    "        print(\"âŒ NO LEVEL SECTIONS FOUND! Trying alternative patterns...\")\n",
    "        \n",
    "        # Try alternative patterns\n",
    "        alt_patterns = [\n",
    "            r'===+([^=]+)===+\\s*\\n(.*?)(?=\\n===+|\\n==|\\n\\{\\{|$)',\n",
    "            r'===+(.*?)\\n(.*?)(?=\\n===+|\\n==|\\n\\{\\{|$)',\n",
    "            r'(Level \\d+|Special|Stage \\d+)[\\s\\S]*?\\[\\[(.*?)\\]\\]'\n",
    "        ]\n",
    "        \n",
    "        for i, pattern in enumerate(alt_patterns):\n",
    "            alt_matches = list(re.finditer(pattern, heroes_section, re.DOTALL))\n",
    "            print(f\"Alternative pattern {i+1}: Found {len(alt_matches)} matches\")\n",
    "            for match in alt_matches:\n",
    "                print(f\"  Match: {match.groups()}\")\n",
    "    \n",
    "    for i, match in enumerate(level_matches):\n",
    "        level_name = match.group(1).strip()\n",
    "        level_content = match.group(2).strip()\n",
    "        \n",
    "        print(f\"\\nðŸ“Š LEVEL {i+1}: {level_name}\")\n",
    "        print(f\"   Content: '{level_content}'\")\n",
    "        \n",
    "        # Extract hero names\n",
    "        heroes = []\n",
    "        \n",
    "        # Method: Find all wikilinks\n",
    "        wikilink_heroes = re.findall(r'\\[\\[([^\\]|]+)(?:\\|[^\\]]*)?\\]\\]', level_content)\n",
    "        print(f\"   Wikilinks found: {wikilink_heroes}\")\n",
    "        \n",
    "        for hero in wikilink_heroes:\n",
    "            hero_clean = hero.strip()\n",
    "            if hero_clean and hero_clean not in heroes:\n",
    "                heroes.append(hero_clean)\n",
    "        \n",
    "        print(f\"   âœ… FINAL HEROES: {heroes}\")\n",
    "        \n",
    "        if heroes:\n",
    "            episode_data[level_name] = heroes\n",
    "        else:\n",
    "            print(f\"   âŒ NO HEROES EXTRACTED from {level_name}\")\n",
    "    \n",
    "    return episode_data\n",
    "\n",
    "def parse_episode_page_final(page: pwb.Page) -> Dict[str, List[str]]:\n",
    "    \"\"\"Final parser that handles the actual wiki format\"\"\"\n",
    "    episode_data = {}\n",
    "    wikitext = page.text\n",
    "    \n",
    "    # Find heroes section\n",
    "    heroes_match = re.search(r'== Heroes of MK \\d+ ==\\s*\\n(.*?)(?=\\n==|\\n\\{\\{|$)', wikitext, re.DOTALL)\n",
    "    if not heroes_match:\n",
    "        return {}\n",
    "    \n",
    "    heroes_section = heroes_match.group(1)\n",
    "    \n",
    "    # Find all level subsections - more flexible pattern\n",
    "    level_pattern = r'===+\\s*([^=]+)\\s*===+\\s*\\n(.*?)(?=\\n===+|\\n==|\\n\\{\\{|$)'\n",
    "    level_matches = re.finditer(level_pattern, heroes_section, re.DOTALL)\n",
    "    \n",
    "    for match in level_matches:\n",
    "        level_name = match.group(1).strip()\n",
    "        level_content = match.group(2).strip()\n",
    "        \n",
    "        # Only process if it looks like a level heading\n",
    "        if not any(keyword in level_name.lower() for keyword in ['level', 'special', 'stage', 'lvl']):\n",
    "            continue\n",
    "        \n",
    "        # Extract all wikilinks\n",
    "        hero_matches = re.findall(r'\\[\\[([^\\]|]+)(?:\\|[^\\]]*)?\\]\\]', level_content)\n",
    "        heroes = []\n",
    "        \n",
    "        for hero in hero_matches:\n",
    "            hero_clean = hero.strip()\n",
    "            if hero_clean and hero_clean not in heroes:\n",
    "                heroes.append(hero_clean)\n",
    "        \n",
    "        if heroes:\n",
    "            episode_data[level_name] = heroes\n",
    "    \n",
    "    return episode_data\n",
    "\n",
    "# Test with MK 17 first\n",
    "print(\"Testing extraction with MK 17...\")\n",
    "mk17_page = pwb.Page(site, \"MK 17\")\n",
    "if mk17_page.exists():\n",
    "    # First debug to see what's happening\n",
    "    debug_data = debug_episode_extraction(mk17_page)\n",
    "    print(f\"\\nðŸŽ¯ DEBUG RESULT: {debug_data}\")\n",
    "    \n",
    "    # Then use the final parser\n",
    "    final_data = parse_episode_page_final(mk17_page)\n",
    "    print(f\"ðŸŽ¯ FINAL RESULT: {final_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee3d68ca-3310-4706-b086-a0cd78479bd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MK 3': {'Level 4': ['The Red Captain']}, 'MK 4': {'Level 6': ['The Orange Captain', 'The Orange Fighter'], 'Level 5': ['The Orange Berserker', 'The Yellow Captain'], 'Level 3': ['The Magenta King']}, 'MK 5': {'Level 4': ['Mireille (MK 5)']}, 'MK 6': {'Level 3': ['Thalia'], 'Special': ['Pherthy']}, 'MK 7': {'Level 6': ['Zaria'], 'Level 4': ['Average Silksong Fan'], 'Level 3': ['Joanwerd']}, 'MK 8': {'Level 8': ['Trigger'], 'Level 7': ['Verbole (MK 8)', 'Da Gaming Boi'], 'Level 6': ['Anya', 'Frithpaul', 'Aiden Lucky', 'Ethelse', 'Manntho', 'Delgundleof', 'Marbelous Racing'], 'Level 5': ['Obstagoon the Mastermind', 'Blox Dealer', 'Malte V', 'Beorthird', 'Helmvid', 'Nightlock', 'Kozladoev', 'Han Chen', 'Pherord', 'Mireille (MK 8)', 'Gia Thuong Nguyen', 'Tolry', 'Jeff Heff', 'Dorgrif'], 'Level 4': ['Dead Buter', 'Treee', 'Category:Episodes', 'zh:MK 8']}, 'MK 9': {'Level 3': ['Warinus', 'Category:Episodes', 'zh:MK 9']}, 'MK 10': {'Level 6': ['Agobard'], 'Level 5': ['Ferumald', 'Amara', 'Crispin'], 'Level 4': ['Caelia', 'Wibert', 'De La Place', 'Theotpert', 'Category:Episodes', 'zh:MK 10']}, 'MK 11': {'Level 5': ['Penthesilea']}, 'MK 12': {'Level 5': ['Watty'], 'Level 4': ['Cro/MK 12'], 'Level 3': ['Gomes']}, 'MK 13': {'Level 9': ['Cavallaro'], 'Level 6': ['Assemani', 'Canavaro'], 'Level 4': ['Ror', 'Deardorff', 'Hyrtacus', 'Nathstan', 'Zeuxidamos'], 'Level 3': ['Sede']}, 'MK 14': {'Level 6': ['Gerhart'], 'Level 4': ['Pisont', 'De Freitas', 'Chalres'], 'Level 3': ['Hewmeri', 'Linckford', 'Category:Episodes', 'zh:MK 14']}, 'MK 15': {'Level 5': ['Gilodis', 'NoahZou', 'Category:Episodes', 'zh:MK 15']}, 'MK 16': {'Level 7': ['Predstava'], 'Level 6': ['KTOTO'], 'Level 4': ['Sofjet'], 'Level 3': ['Apple_Pineapple', 'Category:Episodes', 'zh:MK 16']}, 'MK 17': {'Level 6': ['Nezumi', 'Spectrazon', 'Sinep Egral'], 'Level 5': ['Pingspikes', 'Predstava II', 'Linvala Hop'], 'Level 4': ['Azygrazy', 'Dawnfury', 'Dalancer', 'Brydon']}, 'MK 18': {'Level 8': ['Drewdrinks'], 'Level 5': ['Dodspiral Li', 'Tristan', 'Mellsher'], 'Level 4': ['Faubosticaro', 'Alphabengal', 'Jey Saul', 'Goodcow', 'KrystiianZombie II']}, 'MK 19': {'Level 7': ['Mecona'], 'Level 5': ['Cryptic', 'Emko'], 'Level 4': ['Examiner', 'Ruiangfu', '(b)engel IV', 'AloXlo IV', 'Clutchiq'], 'Level 3': ['Dc', 'Leixiang', 'Hiron', 'Zytwave'], 'Special': ['Augustus', 'Dark Warrior']}, 'MK 20': {'Level 8': ['Sangyu'], 'Level 7': ['Pretox', 'Bitdotdo'], 'Level 6': ['Parkinson'], 'Level 5': ['Matheuscam'], 'Level 4': ['Kall Moss/MK 20', 'Tchef', 'Gunaar', '(b)engel V', 'Birb']}, 'MK 21': {'Level 8': ['Pretox', 'Rosemunda'], 'Level 7': ['Arichnope', 'Voultyre'], 'Level 6': ['Getpunnedon', 'Zfd'], 'Level 5': ['Andy III', 'Adelid', 'Desbiens', 'Joe', 'Givgan'], 'Level 4': ['Louisa', 'Mini-Rus', 'Xlc', 'Shy Guy', 'Askgar', 'Cro'], 'Level 3': ['JYAR III', 'Corncrusader', 'Donston']}, 'MK 22': {'Level 9': ['Askgar'], 'Level 7': ['Noinfo', 'Ellioteaster'], 'Level 5': ['Donston', 'Corncrusader', 'Kingowl', 'Unklerod', 'Gavzino'], 'Level 4': ['Mrpotatofox', 'Louisa', 'Timm', 'Mini-Rus', 'Yassir']}, 'MK 23': {'Level 9': ['Florymonde'], 'Level 7': ['Milkisgood'], 'Level 5': ['Donston', 'Verbole (MK 23)', 'Kiriandino', 'Kikoin'], 'Level 4': ['Gietl', 'Nell', 'Leudbald', 'Barnier', 'Cmwolfmagic', 'Hikurai', 'FancyPancy', 'Morgott', 'Fuzzysir', 'Shiloh', 'Yassir', 'Xlc', 'Gunner Sexton VIII', 'TheDragonWarden']}, 'MK 24': {'Level 7': ['Louisa', 'Wheezer'], 'Level 6': ['Herenfrida', 'Alpha', \"Fred'niel\", 'Andy III'], 'Level 5': ['Theoverlord', 'Chriasaron', 'Axis II', 'Corncrusader', 'Thitam', 'True Warrior'], 'Level 4': ['Alexrets', 'Kittylord', 'Wallahijr', 'Leinkard', 'Crazyb', 'Lysomere', 'Wafer', 'Yokannius'], 'Level 3': ['Alfa', 'Muffinskill X']}, 'MK 25': {'Level 9': ['Gunner Sexton X'], 'Level 4': ['Aeaces', 'Juey', 'Kroma', 'Leudbald', 'IridumSky IV'], 'Level 3': ['Luli', 'Jayhemma', 'Mop Man', 'Tseg', 'SaltyBreadFairy', 'Jordan Tyo IX']}, 'MK 26': {'Level 7': ['Czopin'], 'Level 6': ['Mediocre'], 'Level 5': ['Wertsmerts', 'Red Sergeant', 'Andy VIII'], 'Level 4': ['Shuck', 'Neville', 'Felix Seguda', 'Kolin', 'Anshelmus', 'Shaklehuk', 'Moppy Bobby', 'Consaints'], 'Level 3': ['IridumSky V', 'Homebound', 'Hikurai', 'Santo', 'Keto II', 'Hiyahgg', 'Dirigiblecat', 'Valsorys', 'Rojo Nico II', 'Syuvi I', 'A French Man']}, 'MK 27': {'Level 10': ['Toby II'], 'Level 8': ['Imelda'], 'Level 6': ['Fais', 'Muffinskill XIII'], 'Level 5': ['Leea', 'Irida'], 'Level 4': ['Hasangjekaj', 'Manipul', 'Xlc', 'Aintzile'], 'Level 3': ['Obstagoon V', 'Stippo (MK 27)', 'Dahea'], 'Special': ['Egburt']}, 'MK 28': {'Level 8': ['Paragoonnova VIII', 'Alfgarda'], 'Level 6': ['Andy X', 'Zaakit', 'Herenfrida'], 'Level 5': ['Rupert', 'Warriornest', 'Adelid', 'Helfenbein', 'Roino', 'Syuvi IV'], 'Level 4': ['Coward III', 'Kittvulpin', 'Zeenow'], 'Level 3': ['Faldron', 'William I', 'Dudeman', 'Phemiec', 'Goettinger', 'Muffinskill XIV', 'Pueranus', 'Wang Hongwen']}, 'MK 29': {'Level 10': ['Bertie', 'Wilpikle II'], 'Level 9': ['Jacklooney II', 'Lulu II'], 'Level 8': ['Aristonike', 'Ghazghkull', 'Lumi II'], 'Level 7': ['Morningside', 'Cjshammy II', 'Retinazer', 'Royce', 'Zfd', 'Mistacow', 'MarÄenko II'], 'Level 6': ['Kall Moss II (MK 29)', 'Palmiteiro II', 'Kamil II', 'Keto II', 'Zigred', 'Rupert', 'Haikodo (MK 29)', 'Ilyannias', 'Leea (MK 29)'], 'Level 5': ['(b)engel XIV', 'Joounii II', 'Wolf', 'Kaithesink', 'Wafer VI', 'Odaseus', 'Gavzino', 'Mokou', 'Dvidio', 'Damian', 'Tarnation', 'Zephiro', 'Nynxya II', 'Antheia', 'Loki', 'Probar II', 'Sofjet  II (MK 29)']}, 'MK 30': {'Level 9': ['MrBall II', 'Landerra'], 'Level 8': ['Kasli'], 'Level 7': ['Adam', 'Antony Cag II', 'Voultyre'], 'Level 6': ['Cuthbrid', 'Mediocre'], 'Level 5': ['Novorsky I', 'Chara', 'Ricolda'], 'Level 4': ['Wilecoc', 'Fenrir IV'], 'Level 3': ['Stacosha', 'Rodrigo', 'MarquesTreasures', 'Rojo Nico II/MK 30', 'Wewelgamer']}, 'MK 31': {'Level 12': ['Kall Moss/MK 31'], 'Level 10': ['Ischnaroth', 'Dafida'], 'Level 8': ['Oiia'], 'Level 7': ['Vixenarrow'], 'Level 6': ['Gelzoniansus', 'Joounii II', 'Stanmak'], 'Level 5': ['Mbsj', 'Meow', 'Parapa', 'Poliboli', 'Lavendar', 'JYAR/MK 31'], 'Level 4': ['Des Moutiers', 'Caoefa', 'Brotatochips II']}, 'MK 32': {'Level 16': ['Syuvi IX'], 'Level 13': ['Constantine'], 'Level 9': ['MrBall II'], 'Level 8': ['Kamijoutoma', 'Austin M II', 'Monkeyman'], 'Level 7': ['MagnaCarta II', 'Jacklooney II (MK 32)', 'Ellioteaster'], 'Level 5': ['(b)engel XVI', 'Lulu II', 'Guitai III', 'Sofjet II (MK 32)', 'Adam N II', 'Givgan']}, 'MK 33': {'Level 16': ['Syuvi IX'], 'Level 13': ['Kall Moss/MK 31'], 'Level 10': ['Ischnaroth', 'Wilpikle II', 'Bertie', 'Bischoff'], 'Level 6': ['Algomarbler II'], 'Level 5': ['Zergray', 'Green Ball'], 'Level 4': ['Ingeram', 'Technomancer II', 'Comeleofu']}, 'MK 34': {'Level 10': ['Dr Gherman', 'ToiletPaper'], 'Level 8': ['Abil'], 'Level 7': ['AgentKat'], 'Level 6': ['Mr Xing', 'Herenfrida'], 'Level 5': ['Muffinskill XVIII', 'Lear'], 'Level 4': ['SQbuilder', 'Hubard', 'Aregnorak', 'Egglert', 'Thelord'], 'Level 3': ['Bagio', 'Gudako Emiya', 'Spqr', 'Areston', 'Vorbius', 'Arcadious', 'AzsakVonTriger']}, 'MK 35': {'Level 17': ['Galakktika Starfront'], 'Level 15': ['Caleb of spades'], 'Level 7': ['Snorlax', 'Jacklooney II (MK 32)'], 'Level 6': ['Kahu', 'Baronti', 'Drustan'], 'Level 5': ['Sofjet II'], 'Level 4': ['Hamon', 'Lemon lupin reuben', 'Chevalier Maudit', 'imnotbadinobbys', 'Passemier', 'Daindeer II'], 'Level 3': ['Lillturimn Hawk']}, 'MK 36': {'Level 10': ['Walpurgisnacht', 'Joanwerd II'], 'Level 9': ['Makmix'], 'Level 8': ['Egan Birgen'], 'Level 7': ['Galoer', 'Wangxiaotao', 'Morgott'], 'Level 6': ['Lil Timmy', 'Hyunwoo II'], 'Level 5': ['JYAR VI', 'Liutprand II', 'Black Venom II', 'Princeoftara'], 'Level 4': ['Halwig II', 'Ailmar', 'DVeniceoperator II'], 'Level 3': ['Muffinskill XX', 'Syuvi XV', 'Lukarian7 III', 'SchlecterName', 'Ricard II', 'Superpizzafan', 'bathalgathizer II']}, 'MK 37': {'Level 9': ['Loser', 'Trestics Reti'], 'Level 7': ['Robusta VII', 'Jeaie', 'Ostendarp'], 'Level 6': ['Intxauspe'], 'Level 4': ['Hyunwoo II/MK 37', 'Sabir', 'Donciuex'], 'Level 3': ['Snoozepilled XII', 'Kalare', 'Camdenmagne', 'The Ramon II', 'Karl', 'Uronea', 'Cyclic', 'Fireskanpat II', 'Homura', 'Anabell']}}\n"
     ]
    }
   ],
   "source": [
    "import pywikibot as pwb\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, List\n",
    "\n",
    "site = pwb.Site(\"en\", \"marble_kingdoms\")\n",
    "site.login()\n",
    "\n",
    "def parse_episode_page_flexible(page: pwb.Page) -> Dict[str, List[str]]:\n",
    "    \"\"\"Flexible parser that handles different formatting variations\"\"\"\n",
    "    episode_data = {}\n",
    "    wikitext = page.text\n",
    "    \n",
    "    # More flexible pattern to find heroes section - handles MK34, MK 34, etc.\n",
    "    heroes_patterns = [\n",
    "        r'==\\s*Heroes of MK\\s*\\d+\\s*==\\s*\\n(.*?)(?=\\n==[^=]|\\{\\{|$)',\n",
    "        r'==\\s*Heroes of Marble Kingdoms\\s*\\d+\\s*==\\s*\\n(.*?)(?=\\n==[^=]|\\{\\{|$)',\n",
    "        r'==\\s*Heroes\\s*==\\s*\\n(.*?)(?=\\n==[^=]|\\{\\{|$)',\n",
    "        r'===+\\s*Heroes\\s*===+\\s*\\n(.*?)(?=\\n==[^=]|\\{\\{|$)'\n",
    "    ]\n",
    "    \n",
    "    heroes_section = None\n",
    "    for pattern in heroes_patterns:\n",
    "        heroes_match = re.search(pattern, wikitext, re.DOTALL | re.IGNORECASE)\n",
    "        if heroes_match:\n",
    "            heroes_section = heroes_match.group(1)\n",
    "            break\n",
    "    \n",
    "    if not heroes_section:\n",
    "        print(f\"  No heroes section found in {page.title()} with any pattern\")\n",
    "        return {}\n",
    "    \n",
    "    # Find all level sections - handle various level formats\n",
    "    level_pattern = r'===+\\s*(Level\\s*\\d+|Special|Stage\\s*\\d+|Lvl\\s*\\d+)\\s*===+\\s*\\n(.*?)(?=\\n===+\\s*(?:Level|Special|Stage|Lvl)|\\n==[^=]|\\{\\{|$)'\n",
    "    level_matches = list(re.finditer(level_pattern, heroes_section, re.DOTALL | re.IGNORECASE))\n",
    "    \n",
    "    if not level_matches:\n",
    "        # Try alternative pattern without the lookahead\n",
    "        level_pattern_alt = r'===+\\s*(Level\\s*\\d+|Special|Stage\\s*\\d+|Lvl\\s*\\d+)\\s*===+\\s*\\n(.*)'\n",
    "        level_matches = list(re.finditer(level_pattern_alt, heroes_section, re.DOTALL | re.IGNORECASE))\n",
    "    \n",
    "    for match in level_matches:\n",
    "        level_name = match.group(1).strip()\n",
    "        level_content = match.group(2).strip()\n",
    "        \n",
    "        # Extract all wikilinks\n",
    "        hero_matches = re.findall(r'\\[\\[([^\\]|]+)(?:\\|[^\\]]*)?\\]\\]', level_content)\n",
    "        heroes = []\n",
    "        \n",
    "        for hero in hero_matches:\n",
    "            hero_clean = hero.strip()\n",
    "            if hero_clean and hero_clean not in heroes:\n",
    "                heroes.append(hero_clean)\n",
    "        \n",
    "        if heroes:\n",
    "            episode_data[level_name] = heroes\n",
    "    \n",
    "    return episode_data\n",
    "\n",
    "def debug_specific_episodes():\n",
    "    \"\"\"Debug specific episodes that are failing\"\"\"\n",
    "    problematic_episodes = [34, 35, 36]\n",
    "    \n",
    "    for ep_num in problematic_episodes:\n",
    "        page_title = f\"MK {ep_num}\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"DEBUGGING {page_title}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        page = pwb.Page(site, page_title)\n",
    "        if page.exists():\n",
    "            # First, let's see the raw content around where heroes should be\n",
    "            wikitext = page.text\n",
    "            \n",
    "            # Look for any mention of \"heroes\" in the text\n",
    "            heroes_lines = []\n",
    "            lines = wikitext.split('\\n')\n",
    "            for i, line in enumerate(lines):\n",
    "                if 'hero' in line.lower():\n",
    "                    heroes_lines.append((i, line))\n",
    "                    # Show context around this line\n",
    "                    start = max(0, i-3)\n",
    "                    end = min(len(lines), i+4)\n",
    "                    print(f\"\\nFound 'hero' at line {i}:\")\n",
    "                    for j in range(start, end):\n",
    "                        marker = \">>> \" if j == i else \"    \"\n",
    "                        print(f\"{marker}{j}: {lines[j]}\")\n",
    "            \n",
    "            # Now try the flexible parser\n",
    "            data = parse_episode_page_flexible(page)\n",
    "            print(f\"\\nParser result: {data}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"Page {page_title} not found\")\n",
    "\n",
    "def get_all_episode_data_fixed():\n",
    "    \"\"\"Get data for all episodes with improved parsing\"\"\"\n",
    "    all_data = {}\n",
    "    \n",
    "    for episode_num in range(3, 38):\n",
    "        page_title = f\"MK {episode_num}\"\n",
    "        try:\n",
    "            page = pwb.Page(site, page_title)\n",
    "            if page.exists():\n",
    "                print(f\"Processing {page_title}...\")\n",
    "                data = parse_episode_page_flexible(page)\n",
    "                if data:\n",
    "                    all_data[page_title] = data\n",
    "                    print(f\"  âœ… Found {len(data)} levels, {sum(len(h) for h in data.values())} heroes\")\n",
    "                else:\n",
    "                    print(f\"  âš ï¸  No heroes found in {page_title}\")\n",
    "                    # For problematic episodes, let's debug more\n",
    "                    if episode_num >= 34:\n",
    "                        debug_episode_content(page)\n",
    "            else:\n",
    "                print(f\"  âŒ Page {page_title} not found\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ Error with {page_title}: {e}\")\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "def debug_episode_content(page: pwb.Page):\n",
    "    \"\"\"Debug the content of a specific episode\"\"\"\n",
    "    wikitext = page.text\n",
    "    print(f\"  Debugging {page.title()} content...\")\n",
    "    \n",
    "    # Look for the exact heroes section structure\n",
    "    lines = wikitext.split('\\n')\n",
    "    for i, line in enumerate(lines):\n",
    "        if 'heroes' in line.lower() and '==' in line:\n",
    "            print(f\"  Found potential heroes heading at line {i}: {line}\")\n",
    "            # Show surrounding content\n",
    "            for j in range(max(0, i-2), min(len(lines), i+15)):\n",
    "                marker = \" --> \" if '===' in lines[j] and 'level' in lines[j].lower() else \"     \"\n",
    "                print(f\"  {j:3d}{marker}{lines[j]}\")\n",
    "            break\n",
    "'''\n",
    "# First debug the problematic episodes\n",
    "print(\"Debugging problematic episodes (34, 35, 36)...\")\n",
    "debug_specific_episodes()\n",
    "\n",
    "# Then process all episodes\n",
    "print(\"\\n\\nProcessing all episodes...\")\n",
    "all_episodes_data = get_all_episode_data_fixed()\n",
    "\n",
    "# Save results\n",
    "with open('marble_kingdoms_heroes.json', 'w') as f:\n",
    "    json.dump(all_episodes_data, f, indent=2)\n",
    "print(f\"\\nðŸ’¾ Saved data for {len(all_episodes_data)} episodes\")\n",
    "\n",
    "# Show summary\n",
    "print(\"\\nðŸ“Š SUMMARY:\")\n",
    "for episode, levels in all_episodes_data.items():\n",
    "    hero_count = sum(len(heroes) for heroes in levels.values())\n",
    "    print(f\"{episode}: {len(levels)} levels, {hero_count} heroes\")\n",
    "'''\n",
    "print(all_episodes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6769a3f0-0e21-43bf-8783-33340650e29b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
